{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNBT1_zC9lg6",
        "outputId": "242e9a67-fb84-4f3a-9f43-7b1783fcbff6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "-lqZ0QhGUb30",
        "outputId": "488ca1a4-5d6d-47f3-8476-2ef33a2cdb49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fips</th>\n",
              "      <th>name</th>\n",
              "      <th>current_year_pop</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>59095</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>Baldwin</td>\n",
              "      <td>239294</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>Barbour</td>\n",
              "      <td>24964</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>Bibb</td>\n",
              "      <td>22477</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1009</td>\n",
              "      <td>Blount</td>\n",
              "      <td>59041</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fips     name  current_year_pop    State\n",
              "1  1001  Autauga             59095  Alabama\n",
              "2  1003  Baldwin            239294  Alabama\n",
              "3  1005  Barbour             24964  Alabama\n",
              "4  1007     Bibb             22477  Alabama\n",
              "5  1009   Blount             59041  Alabama"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nat_pop = pd.read_csv(\"Data\\Population\\PopulationReport.csv\")\n",
        "AL_pop = pd.read_csv(\"Data\\Population\\PopulationReportAlabama.csv\")\n",
        "AL_pop[\"State\"] = \"Alabama\"\n",
        "AK_pop = pd.read_csv(\"Data\\Population\\PopulationReportArkansas.csv\")\n",
        "AK_pop[\"State\"] = \"Arkansas\"\n",
        "FL_pop = pd.read_csv(\"Data\\Population\\PopulationReportFlorida.csv\")\n",
        "FL_pop[\"State\"] = \"Florida\"\n",
        "GA_pop = pd.read_csv(\"Data\\Population\\PopulationReportGeorgia.csv\")\n",
        "GA_pop[\"State\"] = \"Georgia\"\n",
        "KY_pop = pd.read_csv(\"Data\\Population\\PopulationReportKentucky.csv\")\n",
        "KY_pop[\"State\"] = \"Kentucky\"\n",
        "LA_pop = pd.read_csv(\"Data\\Population\\PopulationReportLouisiana.csv\")\n",
        "LA_pop[\"State\"] = \"Louisiana\"\n",
        "MD_pop = pd.read_csv(\"Data\\Population\\PopulationReportMaryland.csv\")\n",
        "MD_pop[\"State\"] = \"Maryland\"\n",
        "MS_pop = pd.read_csv(\"Data\\Population\\PopulationReportMississippi.csv\")\n",
        "MS_pop[\"State\"] = \"Mississippi\"\n",
        "NC_pop = pd.read_csv(\"Data\\Population\\PopulationReportNorthCarolina.csv\")\n",
        "NC_pop[\"State\"] = \"North Carolina\"\n",
        "SC_pop = pd.read_csv(\"Data\\Population\\PopulationReportSouthCarolina.csv\")\n",
        "SC_pop[\"State\"] = \"South Carolina\"\n",
        "TN_pop = pd.read_csv(\"Data\\Population\\PopulationReportTennessee.csv\")\n",
        "TN_pop[\"State\"] = \"Tennessee\"\n",
        "VA_pop = pd.read_csv(\"Data\\Population\\PopulationReportVirginia.csv\")\n",
        "VA_pop[\"State\"] = \"Virginia\"\n",
        "WV_pop = pd.read_csv(\"Data\\Population\\PopulationReportWestVirginia.csv\")\n",
        "WV_pop[\"State\"] = \"West Virginia\"\n",
        "\n",
        "test_cat = pd.concat([AL_pop, AK_pop,FL_pop,GA_pop,KY_pop, LA_pop,MD_pop,MS_pop,SC_pop,TN_pop, VA_pop, WV_pop, NC_pop],ignore_index=True).dropna()\n",
        "test_cat = test_cat.replace(',','', regex=True)\n",
        "\n",
        "test_cat = test_cat.astype({\"current_year\" : \"int32\"})\n",
        "\n",
        "\n",
        "test_cat.sort_values(\"current_year\",ascending=False).head()\n",
        "\n",
        "test_cat = test_cat[[\"fips\",\"name\",\"current_year\",\"State\"]]\n",
        "\n",
        "test_cat.sort_values(\"current_year\",ascending=False).head()\n",
        "\n",
        "pop_df = test_cat.rename(columns = {\"current_year\" : \"current_year_pop\"})\n",
        "pop_df.head().sort_values(\"name\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 2 fields in line 59, saw 9\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\donit\\Documents\\cs216\\project\\CS_216_Project_Exploratory_Notebook.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/donit/Documents/cs216/project/CS_216_Project_Exploratory_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m AL_edu_cc \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mData\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mEducation\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mEducationReport-Alabama-CC.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/donit/Documents/cs216/project/CS_216_Project_Exploratory_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m AK_edu_cc \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEducation\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEducationReport-Arkansas-CC.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/donit/Documents/cs216/project/CS_216_Project_Exploratory_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m FL_edu_cc \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEducation\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEducationReport-Florida-CC.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   1255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\donit\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 59, saw 9\n"
          ]
        }
      ],
      "source": [
        "\n",
        "AL_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Alabama-CC.csv\")\n",
        "AK_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Arkansas-CC.csv\")\n",
        "FL_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Florida-CC.csv\")\n",
        "GA_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Georgia-CC.csv\")\n",
        "KY_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Kentucky-CC.csv\")\n",
        "LA_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Louisiana-CC.csv\")\n",
        "MD_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Maryland-CC.csv\")\n",
        "MS_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Mississippi-CC.csv\")\n",
        "NC_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-NorthCarolina-CC.csv\")\n",
        "SC_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-SouthCarolina-CC.csv\")\n",
        "TN_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Tennessee-CC.csv\")\n",
        "VA_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-Virginia-CC.csv\")\n",
        "WV_edu_cc = pd.read_csv(\"Data\\Education\\EducationReport-WestVirginia-CC.csv\")\n",
        "\t  \n",
        "AL_edu_cc[\"State\"] = \"Alabama\"          \n",
        "AK_edu_cc[\"State\"] = \"Arkansas\"         \n",
        "FL_edu_cc[\"State\"] = \"Florida\"          \n",
        "GA_edu_cc[\"State\"] = \"Georgia\"          \n",
        "KY_edu_cc[\"State\"] = \"Kentucky\"         \n",
        "LA_edu_cc[\"State\"] = \"Louisiana\"        \n",
        "MD_edu_cc[\"State\"] = \"Maryland\"         \n",
        "MS_edu_cc[\"State\"] = \"Mississippi\"      \n",
        "NC_edu_cc[\"State\"] = \"North Carolina\"   \n",
        "SC_edu_cc[\"State\"] = \"South Carolina\"   \n",
        "TN_edu_cc[\"State\"] = \"Tennessee\"        \n",
        "VA_edu_cc[\"State\"] = \"Virginia\"          \n",
        "WV_edu_cc[\"State\"] = \"West Virginia\"\n",
        "\n",
        "AL_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "AK_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "FL_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "GA_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "KY_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "LA_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "MD_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "MS_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "NC_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "SC_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "TN_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "VA_edu_cc[\"EducationType\"] = \"Completed College\" \n",
        "WV_edu_cc[\"EducationType\"] = \"Completed College\"\n",
        "\n",
        "AL_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Alabama-NCHS.csv\")\n",
        "AK_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Arkansas-NCHS.csv\")\n",
        "FL_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Florida-NCHS.csv\")\n",
        "GA_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Georgia-NCHS.csv\")\n",
        "KY_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Kentucky-NCHS.csv\")\n",
        "LA_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Louisiana-NCHS.csv\")\n",
        "MD_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Maryland-NCHS.csv\")\n",
        "MS_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Mississippi-NCHS.csv\")\n",
        "NC_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-NorthCarolina-NCHS.csv\")\n",
        "SC_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-SouthCarolina-NCHS.csv\")\n",
        "TN_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Tennessee-NCHS.csv\")\n",
        "VA_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-Virginia-NCHS.csv\")\n",
        "WV_edu_nchs = pd.read_csv(\"Data\\Education\\EducationReport-WestVirginia-NCHS.csv\")\n",
        "\n",
        "AL_edu_nchs[\"State\"] = \"Alabama\"          \n",
        "AK_edu_nchs[\"State\"] = \"Arkansas\"         \n",
        "FL_edu_nchs[\"State\"] = \"Florida\"          \n",
        "GA_edu_nchs[\"State\"] = \"Georgia\"          \n",
        "KY_edu_nchs[\"State\"] = \"Kentucky\"         \n",
        "LA_edu_nchs[\"State\"] = \"Louisiana\"        \n",
        "MD_edu_nchs[\"State\"] = \"Maryland\"         \n",
        "MS_edu_nchs[\"State\"] = \"Mississippi\"      \n",
        "NC_edu_nchs[\"State\"] = \"North Carolina\"   \n",
        "SC_edu_nchs[\"State\"] = \"South Carolina\"   \n",
        "TN_edu_nchs[\"State\"] = \"Tennessee\"        \n",
        "VA_edu_nchs[\"State\"] = \"Virginia\"          \n",
        "WV_edu_nchs[\"State\"] = \"West Virginia\"\n",
        "\t \n",
        "AL_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "AK_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "FL_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "GA_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "KY_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "LA_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "MD_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "MS_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "NC_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "SC_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "TN_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "VA_edu_nchs[\"EducationType\"] = \"Not Completed High School\" \n",
        "WV_edu_nchs[\"EducationType\"] = \"Not Completed High School\"\n",
        "\n",
        "edu_concat_list = [AL_edu_cc,AK_edu_cc,FL_edu_cc,GA_edu_cc,KY_edu_cc,LA_edu_cc,MD_edu_cc,MS_edu_cc,NC_edu_cc,SC_edu_cc,TN_edu_cc,VA_edu_cc,WV_edu_cc,AL_edu_nchs,AK_edu_nchs,FL_edu_nchs,GA_edu_nchs,KY_edu_nchs,LA_edu_nchs,MD_edu_nchs,MS_edu_nchs,NC_edu_nchs,SC_edu_nchs,TN_edu_nchs,VA_edu_nchs,WV_edu_nchs]\n",
        "edu_df = pd.concat(edu_concat_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "avtFDzBwaEmr",
        "outputId": "e62d9cd1-e122-47f6-c57c-0257f9ab6846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['FIPS', 'States', 'County', 'Premature death: Unreliable',\n",
            "       'Premature death: Deaths',\n",
            "       'Premature death: Years of Potential Life Lost Rate',\n",
            "       'Premature death: 95% CI - Low', 'Premature death: 95% CI - High',\n",
            "       'Premature death: Z-Score', 'Premature death: YPLL Rate (AIAN)',\n",
            "       ...\n",
            "       'Severe housing problems: Severe Housing Cost Burden',\n",
            "       'Severe housing problems: Severe Housing Cost Burden 95% CI - Low',\n",
            "       'Severe housing problems: Severe Housing Cost Burden 95% CI - High',\n",
            "       'Severe housing problems: Overcrowding',\n",
            "       'Severe housing problems: Overcrowding 95% CI - Low',\n",
            "       'Severe housing problems: Overcrowding 95% CI - High',\n",
            "       'Severe housing problems: Inadequate Facilities',\n",
            "       'Severe housing problems: Inadequate Facilities 95% CI - Low',\n",
            "       'Severe housing problems: Inadequate Facilities 95% CI - High',\n",
            "       'Severe housing problems: Z-Score'],\n",
            "      dtype='object', length=225)\n"
          ]
        }
      ],
      "source": [
        "AK_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Arkansas Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "AK_obesity.columns = AK_obesity.columns.map(': '.join)\n",
        "\n",
        "AL_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Alabama Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "AL_obesity.columns = AL_obesity.columns.map(': '.join)\n",
        "\n",
        "FL_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Florida Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "FL_obesity.columns = FL_obesity.columns.map(': '.join)\n",
        "\n",
        "GA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Georgia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "GA_obesity.columns = GA_obesity.columns.map(': '.join)\n",
        "\n",
        "KY_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Kentucky Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "KY_obesity.columns = KY_obesity.columns.map(': '.join)\n",
        "\n",
        "LA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Louisiana Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "LA_obesity.columns = LA_obesity.columns.map(': '.join)\n",
        "\n",
        "MD_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Maryland Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "MD_obesity.columns = MD_obesity.columns.map(': '.join)\n",
        "\n",
        "MS_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Mississippi Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "MS_obesity.columns = MS_obesity.columns.map(': '.join)\n",
        "\n",
        "NC_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings North Carolina Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "NC_obesity.columns = NC_obesity.columns.map(': '.join)\n",
        "\n",
        "SC_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings South Carolina Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "SC_obesity.columns = SC_obesity.columns.map(': '.join)\n",
        "\n",
        "TN_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Tennessee Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "TN_obesity.columns = TN_obesity.columns.map(': '.join)\n",
        "\n",
        "VA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Virginia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "VA_obesity.columns = VA_obesity.columns.map(': '.join)\n",
        "\n",
        "WV_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings West Virginia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "WV_obesity.columns = WV_obesity.columns.map(': '.join)\n",
        "\n",
        "df_frames = [AK_obesity, AL_obesity, FL_obesity, GA_obesity, KY_obesity, LA_obesity, MD_obesity, MS_obesity, NC_obesity, SC_obesity, TN_obesity, VA_obesity, WV_obesity]\n",
        "\n",
        "for states in df_frames:\n",
        "    states.rename(columns={ states.columns[0]: \"FIPS\", states.columns[1]: \"States\", states.columns[2]: \"County\" }, inplace=True)\n",
        "\n",
        "all_states = pd.concat(df_frames, axis=0)\n",
        "all_states.head()\n",
        "\n",
        "columns_to_drop = [\n",
        "        'Driving alone to work: % Drive Alone to Work',\n",
        "        'Driving alone to work: 95% CI - Low',\n",
        "        'Driving alone to work: 95% CI - High',\n",
        "        'Driving alone to work: Z-Score',\n",
        "        'Driving alone to work: % Drive Alone (AIAN)',\n",
        "        'Driving alone to work: % Drive Alone (AIAN) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (AIAN) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Asian)',\n",
        "        'Driving alone to work: % Drive Alone (Asian) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Asian) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Black)',\n",
        "        'Driving alone to work: % Drive Alone (Black) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Black) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Hispanic)', \n",
        "        'Driving alone to work: % Drive Alone (Hispanic) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Hispanic) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (white)',\n",
        "        'Driving alone to work: % Drive Alone (white) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (white) 95% CI - High',\n",
        "        'Long commute - driving alone: # Workers who Drive Alone',\n",
        "        'Long commute - driving alone: % Long Commute - Drives Alone',\n",
        "        'Long commute - driving alone: 95% CI - Low',\n",
        "        'Long commute - driving alone: 95% CI - High',\n",
        "        'Long commute - driving alone: Z-Score'\n",
        "       ]\n",
        "\n",
        "all_states.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(all_states.columns)\n",
        "\n",
        "all_states.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HFv9Pw_blDit",
        "outputId": "3d109365-3fcc-4161-e424-d9ab3260418a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fips</th>\n",
              "      <th>county</th>\n",
              "      <th>total_est</th>\n",
              "      <th>under18</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>6242</td>\n",
              "      <td>1912</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>Baldwin</td>\n",
              "      <td>20189</td>\n",
              "      <td>5907</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>Barbour</td>\n",
              "      <td>5548</td>\n",
              "      <td>1857</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>Bibb</td>\n",
              "      <td>3549</td>\n",
              "      <td>941</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1009</td>\n",
              "      <td>Blount</td>\n",
              "      <td>7525</td>\n",
              "      <td>2456</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fips   county  total_est  under18    State\n",
              "1  1001  Autauga       6242     1912  Alabama\n",
              "2  1003  Baldwin      20189     5907  Alabama\n",
              "3  1005  Barbour       5548     1857  Alabama\n",
              "4  1007     Bibb       3549      941  Alabama\n",
              "5  1009   Blount       7525     2456  Alabama"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nat_pov = pd.read_csv(\"Data/Poverty/NationalPoverty.csv\")\n",
        "AL_pov = pd.read_csv(\"Data/Poverty/AlabamaPoverty.csv\")\n",
        "AL_pov[\"State\"] = \"Alabama\"\n",
        "AK_pov = pd.read_csv(\"Data/Poverty/ArkansasPoverty.csv\")\n",
        "AK_pov[\"State\"] = \"Arkansas\"\n",
        "FL_pov = pd.read_csv(\"Data/Poverty/FloridaPoverty.csv\")\n",
        "FL_pov[\"State\"] = \"Florida\"\n",
        "GA_pov = pd.read_csv(\"Data/Poverty/GeorgiaPoverty.csv\")\n",
        "GA_pov[\"State\"] = \"Georgia\"\n",
        "KY_pov = pd.read_csv(\"Data/Poverty/KentuckyPoverty.csv\")\n",
        "KY_pov[\"State\"] = \"Kentucky\"\n",
        "LA_pov = pd.read_csv(\"Data/Poverty/LouisianaPoverty.csv\")\n",
        "LA_pov[\"State\"] = \"Louisiana\"\n",
        "MD_pov = pd.read_csv(\"Data/Poverty/MarylandPoverty.csv\")\n",
        "MD_pov[\"State\"] = \"Maryland\"\n",
        "MS_pov = pd.read_csv(\"Data/Poverty/MississippiPoverty.csv\")\n",
        "MS_pov[\"State\"] = \"Mississippi\"\n",
        "NC_pov = pd.read_csv(\"Data/Poverty/NorthCarolinaPoverty.csv\")\n",
        "NC_pov[\"State\"] = \"North Carolina\"\n",
        "SC_pov = pd.read_csv(\"Data/Poverty/SouthCarolinaPoverty.csv\")\n",
        "SC_pov[\"State\"] = \"South Carolina\"\n",
        "TN_pov = pd.read_csv(\"Data/Poverty/TennesseePoverty.csv\")\n",
        "TN_pov[\"State\"] = \"Tennessee\"\n",
        "VA_pov = pd.read_csv(\"Data/Poverty/VirginiaPoverty.csv\")\n",
        "VA_pov[\"State\"] = \"Virginia\"\n",
        "WV_pov = pd.read_csv(\"Data/Poverty/WestVirginiaPoverty.csv\")\n",
        "WV_pov[\"State\"] = \"West Virginia\"\n",
        "concat_list = [AL_pov, AK_pov, FL_pov, GA_pov, KY_pov, LA_pov, MD_pov, MS_pov, NC_pov, SC_pov, TN_pov, VA_pov, WV_pov]\n",
        "pov_df = pd.concat(concat_list, ignore_index=True)\n",
        "pov_df = pov_df.replace(',','', regex=True)\n",
        "pov_df = pov_df.astype({\"total_est\" : \"int32\"})\n",
        "pov_df = pov_df.astype({\"under18\" : \"int32\"})\n",
        "pov_df = pov_df.drop([\"Textbox93\", \"Textbox96\", \"ruc_code\", \"total_Bmin\", \"total_Bmax\", \"under18_Bmin\", \"under18_Bmax\"], axis=1)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Florida\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Georgia\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"North Carolina\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Tennessee\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Louisiana\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Virginia\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Alabama\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"South Carolina\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Kentucky\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Mississippi\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Maryland\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Arkansas\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"West Virginia\"].index)\n",
        "pov_df.sort_values(\"total_est\",ascending=False).head()\n",
        "pov_df.sort_values(\"fips\",ascending=True).head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>Name</th>\n",
              "      <th>2021</th>\n",
              "      <th>Median Household Income (2020)</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>2.8</td>\n",
              "      <td>67565</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>Baldwin</td>\n",
              "      <td>3.0</td>\n",
              "      <td>71135</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>Barbour</td>\n",
              "      <td>5.7</td>\n",
              "      <td>38866</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>Bibb</td>\n",
              "      <td>3.5</td>\n",
              "      <td>50907</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1009</td>\n",
              "      <td>Blount</td>\n",
              "      <td>2.4</td>\n",
              "      <td>55203</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FIPS      Name  2021  Median Household Income (2020)    State\n",
              "1   1001  Autauga   2.8                           67565  Alabama\n",
              "2   1003  Baldwin   3.0                           71135  Alabama\n",
              "3   1005  Barbour   5.7                           38866  Alabama\n",
              "4   1007     Bibb   3.5                           50907  Alabama\n",
              "5   1009   Blount   2.4                           55203  Alabama"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AL_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Alabama.csv\")\n",
        "AL_unemp['State'] = 'Alabama'\n",
        "AK_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Arkansas.csv\")\n",
        "AK_unemp['State'] = 'Arkansas'\n",
        "FL_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Florida.csv\")\n",
        "FL_unemp['State'] = \"Florida\"\n",
        "GA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Georgia.csv\")\n",
        "GA_unemp['State'] = \"Georgia\"\n",
        "KY_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Kentucky.csv\")\n",
        "KY_unemp['State'] = \"Kentucky\"\n",
        "LA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Louisiana.csv\")\n",
        "LA_unemp['State'] = \"Louisiana\"\n",
        "MD_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Maryland.csv\")\n",
        "MD_unemp['State'] = \"Maryland\"\n",
        "MS_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Mississippi.csv\")\n",
        "MS_unemp['State'] = \"Mississippi\"\n",
        "NC_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_NorthCarolina.csv\")\n",
        "NC_unemp['State'] = \"North Carolina\"\n",
        "SC_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_SouthCarolina.csv\")\n",
        "SC_unemp['State'] = \"South Carolina\"\n",
        "TN_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Tennessee.csv\")\n",
        "TN_unemp['State'] = \"Tennessee\"\n",
        "VA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Virginia.csv\")\n",
        "VA_unemp['State'] = \"Virginia\"\n",
        "WV_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_WestVirginia.csv\")\n",
        "WV_unemp['State'] = \"West Virginia\"\n",
        "concat_list_unemp = [AL_unemp, AK_unemp, FL_unemp, GA_unemp, KY_unemp, LA_unemp, MD_unemp, MS_unemp, NC_unemp, SC_unemp, TN_unemp, VA_unemp, WV_unemp]\n",
        "unemp_df = pd.concat(concat_list_unemp, ignore_index = True)\n",
        "unemp_df = unemp_df.drop([\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"], axis = 1)\n",
        "unemp_df = unemp_df.drop([\"% of State Median HH Income\"], axis = 1)\n",
        "unemp_df = unemp_df.replace(',','', regex = True)\n",
        "\n",
        "\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Alabama'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Arkansas'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Florida'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Georgia'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'North Carolina'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Tennessee'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Louisiana'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Virginia'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Kentucky'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'South Carolina'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Maryland'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Mississppi'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'West Virginia'].index)\n",
        "unemp_df[\"Name\"] = unemp_df[\"Name\"].str.extract(\"([A-Z][a-z]+)\")\n",
        "unemp_df = unemp_df.replace('\\$','', regex = True)\n",
        "unemp_df = unemp_df.astype({\"Median Household Income (2020)\" : \"int32\"})\n",
        "unemp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_df.set_index(\"fips\", inplace=True)\n",
        "pov_df.set_index(\"fips\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fips</th>\n",
              "      <th>county</th>\n",
              "      <th>total_est</th>\n",
              "      <th>under18</th>\n",
              "      <th>State_x</th>\n",
              "      <th>current_year_pop</th>\n",
              "      <th>pop_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>51191</td>\n",
              "      <td>Washington</td>\n",
              "      <td>6856</td>\n",
              "      <td>1583</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>59095</td>\n",
              "      <td>0.116017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>51195</td>\n",
              "      <td>Wise</td>\n",
              "      <td>6984</td>\n",
              "      <td>1854</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>239294</td>\n",
              "      <td>0.029186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>51199</td>\n",
              "      <td>York</td>\n",
              "      <td>3239</td>\n",
              "      <td>919</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>24964</td>\n",
              "      <td>0.129747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>51520</td>\n",
              "      <td>Bristol</td>\n",
              "      <td>2948</td>\n",
              "      <td>1063</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>22477</td>\n",
              "      <td>0.131156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>51540</td>\n",
              "      <td>Charlottesville</td>\n",
              "      <td>7088</td>\n",
              "      <td>1101</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>59041</td>\n",
              "      <td>0.120052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fips           county  total_est  under18   State_x  current_year_pop  \\\n",
              "1001  51191       Washington       6856     1583  Virginia             59095   \n",
              "1003  51195             Wise       6984     1854  Virginia            239294   \n",
              "1005  51199             York       3239      919  Virginia             24964   \n",
              "1007  51520          Bristol       2948     1063  Virginia             22477   \n",
              "1009  51540  Charlottesville       7088     1101  Virginia             59041   \n",
              "\n",
              "      pop_percentage  \n",
              "1001        0.116017  \n",
              "1003        0.029186  \n",
              "1005        0.129747  \n",
              "1007        0.131156  \n",
              "1009        0.120052  "
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "test_df = pd.merge(pov_df, pop_df,left_index=True, right_index = True)\n",
        "test_df = test_df.drop([\"State_y\", \"name\"], axis = 1)\n",
        "test_df = test_df.drop_duplicates()\n",
        "# test_df.head(30)\n",
        "\n",
        "\n",
        "test_df[\"pop_percentage\"] = test_df[\"total_est\"] / test_df[\"current_year_pop\"]\n",
        "\n",
        "test_df.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test commit - jeff"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "d2af80033d1722094a6373da744636ac61bfa5e5b74cfb71636cb2968821b11d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
