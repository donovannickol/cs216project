{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNBT1_zC9lg6",
        "outputId": "242e9a67-fb84-4f3a-9f43-7b1783fcbff6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "-lqZ0QhGUb30",
        "outputId": "488ca1a4-5d6d-47f3-8476-2ef33a2cdb49"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data\\\\Population\\\\PopulationReport.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jeff/Desktop/cs216project/CS_216_Project_Exploratory_Notebook.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeff/Desktop/cs216project/CS_216_Project_Exploratory_Notebook.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nat_pop \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mData\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPopulation\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPopulationReport.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeff/Desktop/cs216project/CS_216_Project_Exploratory_Notebook.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m AL_pop \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPopulation\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPopulationReportAlabama.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeff/Desktop/cs216project/CS_216_Project_Exploratory_Notebook.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m AL_pop[\u001b[39m\"\u001b[39m\u001b[39mState\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAlabama\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data\\\\Population\\\\PopulationReport.csv'"
          ]
        }
      ],
      "source": [
        "nat_pop = pd.read_csv(\"Data\\Population\\PopulationReport.csv\")\n",
        "AL_pop = pd.read_csv(\"Data\\Population\\PopulationReportAlabama.csv\")\n",
        "AL_pop[\"State\"] = \"Alabama\"\n",
        "AK_pop = pd.read_csv(\"Data\\Population\\PopulationReportArkansas.csv\")\n",
        "AK_pop[\"State\"] = \"Arkansas\"\n",
        "FL_pop = pd.read_csv(\"Data\\Population\\PopulationReportFlorida.csv\")\n",
        "FL_pop[\"State\"] = \"Florida\"\n",
        "GA_pop = pd.read_csv(\"Data\\Population\\PopulationReportGeorgia.csv\")\n",
        "GA_pop[\"State\"] = \"Georgia\"\n",
        "KY_pop = pd.read_csv(\"Data\\Population\\PopulationReportKentucky.csv\")\n",
        "KY_pop[\"State\"] = \"Kentucky\"\n",
        "LA_pop = pd.read_csv(\"Data\\Population\\PopulationReportLouisiana.csv\")\n",
        "LA_pop[\"State\"] = \"Louisiana\"\n",
        "MD_pop = pd.read_csv(\"Data\\Population\\PopulationReportMaryland.csv\")\n",
        "MD_pop[\"State\"] = \"Maryland\"\n",
        "MS_pop = pd.read_csv(\"Data\\Population\\PopulationReportMississippi.csv\")\n",
        "MS_pop[\"State\"] = \"Mississippi\"\n",
        "NC_pop = pd.read_csv(\"Data\\Population\\PopulationReportNorthCarolina.csv\")\n",
        "NC_pop[\"State\"] = \"North Carolina\"\n",
        "SC_pop = pd.read_csv(\"Data\\Population\\PopulationReportSouthCarolina.csv\")\n",
        "SC_pop[\"State\"] = \"South Carolina\"\n",
        "TN_pop = pd.read_csv(\"Data\\Population\\PopulationReportTennessee.csv\")\n",
        "TN_pop[\"State\"] = \"Tennessee\"\n",
        "VA_pop = pd.read_csv(\"Data\\Population\\PopulationReportVirginia.csv\")\n",
        "VA_pop[\"State\"] = \"Virginia\"\n",
        "WV_pop = pd.read_csv(\"Data\\Population\\PopulationReportWestVirginia.csv\")\n",
        "WV_pop[\"State\"] = \"West Virginia\"\n",
        "\n",
        "test_cat = pd.concat([AL_pop, AK_pop,FL_pop,GA_pop,KY_pop, LA_pop,MD_pop,MS_pop,SC_pop,TN_pop, VA_pop, WV_pop, NC_pop,],ignore_index=True).dropna()\n",
        "test_cat = test_cat.replace(',','', regex=True)\n",
        "\n",
        "test_cat = test_cat.astype({\"current_year\" : \"int32\"})\n",
        "\n",
        "\n",
        "test_cat.sort_values(\"current_year\",ascending=False).head()\n",
        "\n",
        "test_cat = test_cat[[\"fips\",\"name\",\"current_year\",\"State\"]]\n",
        "\n",
        "test_cat.sort_values(\"current_year\",ascending=False).head()\n",
        "\n",
        "pop_df = test_cat.rename(columns = {\"current_year\" : \"current_year_pop\"})\n",
        "pop_df.head().sort_values(\"name\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "avtFDzBwaEmr",
        "outputId": "e62d9cd1-e122-47f6-c57c-0257f9ab6846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['FIPS', 'States', 'County', 'Premature death: Unreliable',\n",
            "       'Premature death: Deaths',\n",
            "       'Premature death: Years of Potential Life Lost Rate',\n",
            "       'Premature death: 95% CI - Low', 'Premature death: 95% CI - High',\n",
            "       'Premature death: Z-Score', 'Premature death: YPLL Rate (AIAN)',\n",
            "       ...\n",
            "       'Severe housing problems: Severe Housing Cost Burden',\n",
            "       'Severe housing problems: Severe Housing Cost Burden 95% CI - Low',\n",
            "       'Severe housing problems: Severe Housing Cost Burden 95% CI - High',\n",
            "       'Severe housing problems: Overcrowding',\n",
            "       'Severe housing problems: Overcrowding 95% CI - Low',\n",
            "       'Severe housing problems: Overcrowding 95% CI - High',\n",
            "       'Severe housing problems: Inadequate Facilities',\n",
            "       'Severe housing problems: Inadequate Facilities 95% CI - Low',\n",
            "       'Severe housing problems: Inadequate Facilities 95% CI - High',\n",
            "       'Severe housing problems: Z-Score'],\n",
            "      dtype='object', length=225)\n"
          ]
        }
      ],
      "source": [
        "AK_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Arkansas Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "AK_obesity.columns = AK_obesity.columns.map(': '.join)\n",
        "\n",
        "AL_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Alabama Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "AL_obesity.columns = AL_obesity.columns.map(': '.join)\n",
        "\n",
        "FL_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Florida Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "FL_obesity.columns = FL_obesity.columns.map(': '.join)\n",
        "\n",
        "GA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Georgia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "GA_obesity.columns = GA_obesity.columns.map(': '.join)\n",
        "\n",
        "KY_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Kentucky Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "KY_obesity.columns = KY_obesity.columns.map(': '.join)\n",
        "\n",
        "LA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Louisiana Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "LA_obesity.columns = LA_obesity.columns.map(': '.join)\n",
        "\n",
        "MD_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Maryland Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "MD_obesity.columns = MD_obesity.columns.map(': '.join)\n",
        "\n",
        "MS_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Mississippi Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "MS_obesity.columns = MS_obesity.columns.map(': '.join)\n",
        "\n",
        "NC_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings North Carolina Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "NC_obesity.columns = NC_obesity.columns.map(': '.join)\n",
        "\n",
        "SC_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings South Carolina Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "SC_obesity.columns = SC_obesity.columns.map(': '.join)\n",
        "\n",
        "TN_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Tennessee Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "TN_obesity.columns = TN_obesity.columns.map(': '.join)\n",
        "\n",
        "VA_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings Virginia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "VA_obesity.columns = VA_obesity.columns.map(': '.join)\n",
        "\n",
        "WV_obesity = pd.read_excel(\"Data/Obesity/2022 County Health Rankings West Virginia Data - v1.xlsx\",sheet_name = 3, header=[0,1])\n",
        "WV_obesity.columns = WV_obesity.columns.map(': '.join)\n",
        "\n",
        "df_frames = [AK_obesity, AL_obesity, FL_obesity, GA_obesity, KY_obesity, LA_obesity, MD_obesity, MS_obesity, NC_obesity, SC_obesity, TN_obesity, VA_obesity, WV_obesity]\n",
        "\n",
        "for states in df_frames:\n",
        "    states.rename(columns={ states.columns[0]: \"FIPS\", states.columns[1]: \"States\", states.columns[2]: \"County\" }, inplace=True)\n",
        "\n",
        "all_states = pd.concat(df_frames, axis=0)\n",
        "all_states.head()\n",
        "\n",
        "columns_to_drop = [\n",
        "        'Driving alone to work: % Drive Alone to Work',\n",
        "        'Driving alone to work: 95% CI - Low',\n",
        "        'Driving alone to work: 95% CI - High',\n",
        "        'Driving alone to work: Z-Score',\n",
        "        'Driving alone to work: % Drive Alone (AIAN)',\n",
        "        'Driving alone to work: % Drive Alone (AIAN) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (AIAN) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Asian)',\n",
        "        'Driving alone to work: % Drive Alone (Asian) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Asian) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Black)',\n",
        "        'Driving alone to work: % Drive Alone (Black) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Black) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (Hispanic)', \n",
        "        'Driving alone to work: % Drive Alone (Hispanic) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (Hispanic) 95% CI - High',\n",
        "        'Driving alone to work: % Drive Alone (white)',\n",
        "        'Driving alone to work: % Drive Alone (white) 95% CI - Low',\n",
        "        'Driving alone to work: % Drive Alone (white) 95% CI - High',\n",
        "        'Long commute - driving alone: # Workers who Drive Alone',\n",
        "        'Long commute - driving alone: % Long Commute - Drives Alone',\n",
        "        'Long commute - driving alone: 95% CI - Low',\n",
        "        'Long commute - driving alone: 95% CI - High',\n",
        "        'Long commute - driving alone: Z-Score'\n",
        "       ]\n",
        "\n",
        "all_states.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(all_states.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HFv9Pw_blDit",
        "outputId": "3d109365-3fcc-4161-e424-d9ab3260418a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fips</th>\n",
              "      <th>county</th>\n",
              "      <th>total_est</th>\n",
              "      <th>under18</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>12086</td>\n",
              "      <td>Miami-Dade</td>\n",
              "      <td>399797</td>\n",
              "      <td>106575</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>12011</td>\n",
              "      <td>Broward</td>\n",
              "      <td>214119</td>\n",
              "      <td>56676</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>12099</td>\n",
              "      <td>Palm Beach</td>\n",
              "      <td>178480</td>\n",
              "      <td>45103</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>12057</td>\n",
              "      <td>Hillsborough</td>\n",
              "      <td>175650</td>\n",
              "      <td>46039</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>47157</td>\n",
              "      <td>Shelby</td>\n",
              "      <td>174664</td>\n",
              "      <td>61594</td>\n",
              "      <td>Tennessee</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fips        county  total_est  under18      State\n",
              "187  12086    Miami-Dade     399797   106575    Florida\n",
              "150  12011       Broward     214119    56676    Florida\n",
              "194  12099    Palm Beach     178480    45103    Florida\n",
              "172  12057  Hillsborough     175650    46039    Florida\n",
              "893  47157        Shelby     174664    61594  Tennessee"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nat_pov = pd.read_csv(\"Data/Poverty/NationalPoverty.csv\")\n",
        "AL_pov = pd.read_csv(\"Data/Poverty/AlabamaPoverty.csv\")\n",
        "AL_pov[\"State\"] = \"Alabama\"\n",
        "AK_pov = pd.read_csv(\"Data/Poverty/ArkansasPoverty.csv\")\n",
        "AK_pov[\"State\"] = \"Arkansas\"\n",
        "FL_pov = pd.read_csv(\"Data/Poverty/FloridaPoverty.csv\")\n",
        "FL_pov[\"State\"] = \"Florida\"\n",
        "GA_pov = pd.read_csv(\"Data/Poverty/GeorgiaPoverty.csv\")\n",
        "GA_pov[\"State\"] = \"Georgia\"\n",
        "KY_pov = pd.read_csv(\"Data/Poverty/KentuckyPoverty.csv\")\n",
        "KY_pov[\"State\"] = \"Kentucky\"\n",
        "LA_pov = pd.read_csv(\"Data/Poverty/LouisianaPoverty.csv\")\n",
        "LA_pov[\"State\"] = \"Louisiana\"\n",
        "MD_pov = pd.read_csv(\"Data/Poverty/MarylandPoverty.csv\")\n",
        "MD_pov[\"State\"] = \"Maryland\"\n",
        "MS_pov = pd.read_csv(\"Data/Poverty/MississippiPoverty.csv\")\n",
        "MS_pov[\"State\"] = \"Mississippi\"\n",
        "NC_pov = pd.read_csv(\"Data/Poverty/NorthCarolinaPoverty.csv\")\n",
        "NC_pov[\"State\"] = \"North Carolina\"\n",
        "SC_pov = pd.read_csv(\"Data/Poverty/SouthCarolinaPoverty.csv\")\n",
        "SC_pov[\"State\"] = \"South Carolina\"\n",
        "TN_pov = pd.read_csv(\"Data/Poverty/TennesseePoverty.csv\")\n",
        "TN_pov[\"State\"] = \"Tennessee\"\n",
        "VA_pov = pd.read_csv(\"Data/Poverty/VirginiaPoverty.csv\")\n",
        "VA_pov[\"State\"] = \"Virginia\"\n",
        "WV_pov = pd.read_csv(\"Data/Poverty/WestVirginiaPoverty.csv\")\n",
        "WV_pov[\"State\"] = \"West Virginia\"\n",
        "concat_list = [AL_pov, AK_pov, FL_pov, GA_pov, KY_pov, LA_pov, MD_pov, MS_pov, NC_pov, SC_pov, TN_pov, VA_pov, WV_pov]\n",
        "pov_df = pd.concat(concat_list, ignore_index=True)\n",
        "pov_df = pov_df.replace(',','', regex=True)\n",
        "pov_df = pov_df.astype({\"total_est\" : \"int32\"})\n",
        "pov_df = pov_df.astype({\"under18\" : \"int32\"})\n",
        "pov_df = pov_df.drop([\"Textbox93\", \"Textbox96\", \"ruc_code\", \"total_Bmin\", \"total_Bmax\", \"under18_Bmin\", \"under18_Bmax\"], axis=1)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Florida\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Georgia\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"North Carolina\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Tennessee\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Louisiana\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Virginia\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Alabama\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"South Carolina\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Kentucky\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Mississippi\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Maryland\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"Arkansas\"].index)\n",
        "pov_df = pov_df.drop(pov_df[pov_df[\"county\"] == \"West Virginia\"].index)\n",
        "pov_df.sort_values(\"total_est\",ascending=False).head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>Name</th>\n",
              "      <th>2021</th>\n",
              "      <th>Median Household Income (2020)</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>2.8</td>\n",
              "      <td>67565</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>Baldwin</td>\n",
              "      <td>3.0</td>\n",
              "      <td>71135</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>Barbour</td>\n",
              "      <td>5.7</td>\n",
              "      <td>38866</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>Bibb</td>\n",
              "      <td>3.5</td>\n",
              "      <td>50907</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1009</td>\n",
              "      <td>Blount</td>\n",
              "      <td>2.4</td>\n",
              "      <td>55203</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FIPS      Name  2021  Median Household Income (2020)    State\n",
              "1   1001  Autauga   2.8                           67565  Alabama\n",
              "2   1003  Baldwin   3.0                           71135  Alabama\n",
              "3   1005  Barbour   5.7                           38866  Alabama\n",
              "4   1007     Bibb   3.5                           50907  Alabama\n",
              "5   1009   Blount   2.4                           55203  Alabama"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AL_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Alabama.csv\")\n",
        "AL_unemp['State'] = 'Alabama'\n",
        "AK_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Arkansas.csv\")\n",
        "AK_unemp['State'] = 'Arkansas'\n",
        "FL_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Florida.csv\")\n",
        "FL_unemp['State'] = \"Florida\"\n",
        "GA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Georgia.csv\")\n",
        "GA_unemp['State'] = \"Georgia\"\n",
        "KY_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Kentucky.csv\")\n",
        "KY_unemp['State'] = \"Kentucky\"\n",
        "LA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Louisiana.csv\")\n",
        "LA_unemp['State'] = \"Louisiana\"\n",
        "MD_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Maryland.csv\")\n",
        "MD_unemp['State'] = \"Maryland\"\n",
        "MS_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Mississippi.csv\")\n",
        "MS_unemp['State'] = \"Mississippi\"\n",
        "NC_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_NorthCarolina.csv\")\n",
        "NC_unemp['State'] = \"North Carolina\"\n",
        "SC_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_SouthCarolina.csv\")\n",
        "SC_unemp['State'] = \"South Carolina\"\n",
        "TN_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Tennessee.csv\")\n",
        "TN_unemp['State'] = \"Tennessee\"\n",
        "VA_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_Virginia.csv\")\n",
        "VA_unemp['State'] = \"Virginia\"\n",
        "WV_unemp = pd.read_csv(\"Data/Unemployment/UnemploymentReport_WestVirginia.csv\")\n",
        "WV_unemp['State'] = \"West Virginia\"\n",
        "concat_list_unemp = [AL_unemp, AK_unemp, FL_unemp, GA_unemp, KY_unemp, LA_unemp, MD_unemp, MS_unemp, NC_unemp, SC_unemp, TN_unemp, VA_unemp, WV_unemp]\n",
        "unemp_df = pd.concat(concat_list_unemp, ignore_index = True)\n",
        "unemp_df = unemp_df.drop([\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"], axis = 1)\n",
        "unemp_df = unemp_df.drop([\"% of State Median HH Income\"], axis = 1)\n",
        "unemp_df = unemp_df.replace(',','', regex = True)\n",
        "\n",
        "\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Alabama'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Arkansas'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Florida'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Georgia'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'North Carolina'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Tennessee'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Louisiana'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Virginia'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Kentucky'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'South Carolina'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Maryland'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'Mississppi'].index)\n",
        "unemp_df = unemp_df.drop(unemp_df[unemp_df[\"Name\"] == 'West Virginia'].index)\n",
        "unemp_df[\"Name\"] = unemp_df[\"Name\"].str.extract(\"([A-Z][a-z]+)\")\n",
        "unemp_df = unemp_df.replace('\\$','', regex = True)\n",
        "unemp_df = unemp_df.astype({\"Median Household Income (2020)\" : \"int32\"})\n",
        "unemp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test commit - jeff"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "9b1e51001b4a79ac77a09287b57a2f952f9949a3262b36a5f5e48e3a3f37f547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
